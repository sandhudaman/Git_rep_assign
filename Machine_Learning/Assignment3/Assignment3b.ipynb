{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec46bcd",
   "metadata": {},
   "source": [
    "# Assignment Part3b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15070f91",
   "metadata": {},
   "source": [
    "Text data used from :https://www.kaggle.com/ishantjuyal/emotions-in-text\n",
    "File used : Emotion_final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e28cf1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries \n",
    "import pandas as pd \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text = pd.read_csv('Emotion_final.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d49b15",
   "metadata": {},
   "source": [
    "# Clearing Data initiating bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95ff0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.dropna(inplace=True) \n",
    "# Getting text and emotion column \n",
    "y = text['Emotion']\n",
    "X = text['Text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "807ea62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splititing train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebbca3e",
   "metadata": {},
   "source": [
    "# 1. Using ComplementNB and default count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0ae8a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7379621000310655\n",
      "[[ 498   19  165    1  228    0]\n",
      " [  27  391  162    0  208    1]\n",
      " [   7    8 1945    4   73    2]\n",
      " [   5    3  311  101   77    0]\n",
      " [  13   11  115    0 1801    2]\n",
      " [   8   28  116    1   92   15]]\n",
      "Labels: ['happy' 'love' 'surprise' 'sadness' 'anger' 'fear']\n",
      "p0= For Each Label [0.89247312 0.85       0.69118692 0.94392523 0.72650262 0.75      ]\n",
      "r0= For Each Label [0.54665203 0.49556401 0.95389897 0.20321932 0.92739444 0.05769231]\n",
      "p0= Micro-average 0.7379621000310655\n",
      "r0= Micro-average 0.7379621000310655\n"
     ]
    }
   ],
   "source": [
    "# mostof the code will be relativily same throughout with some tweaking\n",
    "# importing classes for accuracy, percision, Complement NB, Confusinon Matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# initiating Complement Naive Bayes Class\n",
    "cnb_clf = ComplementNB()\n",
    "\n",
    "# initiating default count vector\n",
    "cnb_vectorizer = CountVectorizer()   # bag of words \n",
    "\n",
    "#initiating pipeline for trasition\n",
    "cnb_model = Pipeline(steps=[('vectorizer', cnb_vectorizer), ('classifier',cnb_clf)])\n",
    "\n",
    "# Fitting the train model\n",
    "cnb_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = v_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, predictions))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "print(\"Labels:\" ,y_test.unique())\n",
    "print(\"p0= For Each Label\",precision_score(y_test, predictions,average = None))\n",
    "print(\"r0= For Each Label\",recall_score(y_test, predictions,average = None))\n",
    "\n",
    "print(\"p0= Micro-average\",precision_score(y_test, predictions,average = 'micro'))\n",
    "print(\"r0= Micro-average\",recall_score(y_test, predictions,average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a96d4",
   "metadata": {},
   "source": [
    "# 2. Using MultinomialNB and  default count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e1fbb72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7379621000310655\n",
      "[[ 498   19  165    1  228    0]\n",
      " [  27  391  162    0  208    1]\n",
      " [   7    8 1945    4   73    2]\n",
      " [   5    3  311  101   77    0]\n",
      " [  13   11  115    0 1801    2]\n",
      " [   8   28  116    1   92   15]]\n",
      "Labels: ['happy' 'love' 'surprise' 'sadness' 'anger' 'fear']\n",
      "p0= For Each Label [0.89247312 0.85       0.69118692 0.94392523 0.72650262 0.75      ]\n",
      "r0= For Each Label [0.54665203 0.49556401 0.95389897 0.20321932 0.92739444 0.05769231]\n",
      "p0= Micro-average 0.7379621000310655\n",
      "r0= Micro-average 0.7379621000310655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "\n",
    "v_model = Pipeline(steps=[('vectorizer', c_vectorizer), ('classifier',clf)])\n",
    "v_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = v_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, predictions))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "print(\"Labels:\" ,y_test.unique())\n",
    "print(\"p0= For Each Label\",precision_score(y_test, predictions,average = None))\n",
    "print(\"r0= For Each Label\",recall_score(y_test, predictions,average = None))\n",
    "\n",
    "print(\"p0= Micro-average\",precision_score(y_test, predictions,average = 'micro'))\n",
    "print(\"r0= Micro-average\",recall_score(y_test, predictions,average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b8c0e",
   "metadata": {},
   "source": [
    "# 3. Using MultinomialNB and  count Vector(nbag = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "49345dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5908667287977633\n",
      "[[ 260   16  340    0  295    0]\n",
      " [  13  224  298    1  250    3]\n",
      " [   6    2 1784    6  241    0]\n",
      " [   4    2  329   41  121    0]\n",
      " [  16    7  435    1 1483    0]\n",
      " [   7   19  123    1   98   12]]\n",
      "Labels: ['happy' 'love' 'surprise' 'sadness' 'anger' 'fear']\n",
      "p0= For Each Label [0.8496732  0.82962963 0.53913569 0.82       0.59606109 0.8       ]\n",
      "r0= For Each Label [0.28540066 0.28390368 0.8749387  0.08249497 0.76364573 0.04615385]\n",
      "p0= Micro-average 0.5908667287977633\n",
      "r0= Micro-average 0.5908667287977633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB()\n",
    "\n",
    "cnb_vectorizer2 = CountVectorizer(analyzer='word',ngram_range=(2, 2))\n",
    "\n",
    "v_model = Pipeline(steps=[('vectorizer', cnb_vectorizer2), ('classifier',clf2)])\n",
    "v_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = v_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, predictions))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "print(\"Labels:\" ,y_test.unique())\n",
    "print(\"p0= For Each Label\",precision_score(y_test, predictions,average = None))\n",
    "print(\"r0= For Each Label\",recall_score(y_test, predictions,average = None))\n",
    "\n",
    "print(\"p0= Micro-average\",precision_score(y_test, predictions,average = 'micro'))\n",
    "print(\"r0= Micro-average\",recall_score(y_test, predictions,average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65382a43",
   "metadata": {},
   "source": [
    "# 4. Using MultinomialNB and count Vector(n bag = 2) and using stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "497ae778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6644920782851818\n",
      "[[ 439   16  286    0  170    0]\n",
      " [  25  394  234    0  134    2]\n",
      " [  11    8 1774   10  236    0]\n",
      " [  12    1  278  119   87    0]\n",
      " [  14    5  410    1 1512    0]\n",
      " [   5   43  120    0   52   40]]\n",
      "Labels: ['happy' 'love' 'surprise' 'sadness' 'anger' 'fear']\n",
      "p0= For Each Label [0.86758893 0.84368308 0.5718891  0.91538462 0.69009585 0.95238095]\n",
      "r0= For Each Label [0.48188804 0.49936629 0.87003433 0.23943662 0.77857878 0.15384615]\n",
      "p0= Micro-average 0.6644920782851818\n",
      "r0= Micro-average 0.6644920782851818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB()\n",
    "\n",
    "cnb_vectorizer2 = CountVectorizer(analyzer='word',ngram_range=(2, 2),stop_words='english')\n",
    "\n",
    "v_model = Pipeline(steps=[('vectorizer', cnb_vectorizer2), ('classifier',clf2)])\n",
    "v_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = v_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, predictions))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "print(\"Labels:\" ,y_test.unique())\n",
    "print(\"p0= For Each Label\",precision_score(y_test, predictions,average = None))\n",
    "print(\"r0= For Each Label\",recall_score(y_test, predictions,average = None))\n",
    "\n",
    "print(\"p0= Micro-average\",precision_score(y_test, predictions,average = 'micro'))\n",
    "print(\"r0= Micro-average\",recall_score(y_test, predictions,average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb4592",
   "metadata": {},
   "source": [
    "# 5. Using ComplementNB and countVector with stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3dc79ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8757378067722895\n",
      "[[ 769   35   31    8   66    2]\n",
      " [  22  674   30    4   46   13]\n",
      " [  30   31 1837   72   60    9]\n",
      " [   5    5   79  393   14    1]\n",
      " [  38   26   79   12 1778    9]\n",
      " [   6   39   21    0    7  187]]\n",
      "Labels: ['happy' 'love' 'surprise' 'sadness' 'anger' 'fear']\n",
      "p0= For Each Label [0.88390805 0.83209877 0.88444872 0.80368098 0.90208016 0.84615385]\n",
      "r0= For Each Label [0.84412733 0.85424588 0.90093183 0.79074447 0.91555098 0.71923077]\n",
      "p0= Micro-average 0.8757378067722895\n",
      "r0= Micro-average 0.8757378067722895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "cnb_clf = ComplementNB()\n",
    "\n",
    "cnb_vectorizer = CountVectorizer(stop_words='english')  \n",
    "cnb_model = Pipeline(steps=[('vectorizer', cnb_vectorizer), ('classifier',cnb_clf)])\n",
    "\n",
    "cnb_model.fit(X_train, y_train)\n",
    "predictions =cnb_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, predictions))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "print(\"Labels:\" ,y_test.unique())\n",
    "print(\"p0= For Each Label\",precision_score(y_test, predictions,average = None))\n",
    "print(\"r0= For Each Label\",recall_score(y_test, predictions,average = None))\n",
    "\n",
    "print(\"p0= Micro-average\",precision_score(y_test, predictions,average = 'micro'))\n",
    "print(\"r0= Micro-average\",recall_score(y_test, predictions,average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de54ccf",
   "metadata": {},
   "source": [
    "# 6. Using MultinomialNB and countVector(nwords = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "96c920ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.46318732525629075\n",
      "[[ 188   15  419    2  287    0]\n",
      " [  29  141  389    3  224    3]\n",
      " [  58   15 1577   19  370    0]\n",
      " [  19    8  329   34  107    0]\n",
      " [  54   22  826    4 1036    0]\n",
      " [  10   18  148    1   77    6]]\n",
      "Labels: ['happy' 'love' 'surprise' 'sadness' 'anger' 'fear']\n",
      "p0= For Each Label [0.52513966 0.64383562 0.42760304 0.53968254 0.49309852 0.66666667]\n",
      "r0= For Each Label [0.20636663 0.17870722 0.77341834 0.06841046 0.53347065 0.02307692]\n",
      "p0= Micro-average 0.46318732525629075\n",
      "r0= Micro-average 0.46318732525629075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB()\n",
    "\n",
    "cnb_vectorizer2 = CountVectorizer(ngram_range=(3, 3))\n",
    "\n",
    "v_model = Pipeline(steps=[('vectorizer', cnb_vectorizer2), ('classifier',clf2)])\n",
    "v_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = v_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, predictions))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "print(\"Labels:\" ,y_test.unique())\n",
    "print(\"p0= For Each Label\",precision_score(y_test, predictions,average = None))\n",
    "print(\"r0= For Each Label\",recall_score(y_test, predictions,average = None))\n",
    "\n",
    "print(\"p0= Micro-average\",precision_score(y_test, predictions,average = 'micro'))\n",
    "print(\"r0= Micro-average\",recall_score(y_test, predictions,average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9aae91",
   "metadata": {},
   "source": [
    "# 7. Using MultinomialNB and with TfidVectroizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b714cd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6806461634047841\n",
      "[[ 316    8  310    0  277    0]\n",
      " [  13  249  281    0  246    0]\n",
      " [   1    1 1989    0   48    0]\n",
      " [   2    1  372   39   83    0]\n",
      " [   4    2  153    0 1783    0]\n",
      " [   2   17  147    0   88    6]]\n",
      "Labels: ['happy' 'love' 'surprise' 'sadness' 'anger' 'fear']\n",
      "p0= For Each Label [0.93491124 0.89568345 0.61162362 1.         0.70613861 1.        ]\n",
      "r0= For Each Label [0.34687157 0.31558935 0.97547818 0.07847082 0.91812564 0.02307692]\n",
      "p0= Micro-average 0.6806461634047841\n",
      "r0= Micro-average 0.6806461634047841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB()\n",
    "\n",
    "# importing term frequency and inverse term frequencyword counter \n",
    "# this counter is very user ful in normalizing data\n",
    "# Used in test 7 and 8\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english',max_df= .1, min_df = 1)\n",
    "\n",
    "# pipeline using Tfidf vector \n",
    "v_model = Pipeline(steps=[('vectorizer', vectorizer), ('classifier',clf2)])\n",
    "v_model.fit(X_train, y_train)\n",
    "predictions = v_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, predictions))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "print(\"Labels:\" ,y_test.unique())\n",
    "print(\"p0= For Each Label\",precision_score(y_test, predictions,average = None))\n",
    "print(\"r0= For Each Label\",recall_score(y_test, predictions,average = None))\n",
    "\n",
    "print(\"p0= Micro-average\",precision_score(y_test, predictions,average = 'micro'))\n",
    "print(\"r0= Micro-average\",recall_score(y_test, predictions,average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e6e47",
   "metadata": {},
   "source": [
    "# 8. Using ComplementNB and with TfidVectroizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f55b8351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.875116495806151\n",
      "[[ 767   30   40    6   67    1]\n",
      " [  26  658   34    4   57   10]\n",
      " [  29   23 1870   49   58   10]\n",
      " [   5    5   92  380   14    1]\n",
      " [  40   24   86   11 1776    5]\n",
      " [   4   34   26    0   13  183]]\n",
      "Labels: ['happy' 'love' 'surprise' 'sadness' 'anger' 'fear']\n",
      "p0= For Each Label [0.88059701 0.8501292  0.87057728 0.84444444 0.89471033 0.87142857]\n",
      "r0= For Each Label [0.84193194 0.83396705 0.91711623 0.76458753 0.91452111 0.70384615]\n",
      "p0= Micro-average 0.875116495806151\n",
      "r0= Micro-average 0.875116495806151\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "cnb_clf = ComplementNB()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english',max_df= .1, min_df = 1)\n",
    "\n",
    "cnb_model = Pipeline(steps=[('vectorizer',vectorizer), ('classifier',cnb_clf)])\n",
    "\n",
    "cnb_model.fit(X_train, y_train)\n",
    "predictions = cnb_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, predictions))\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "print(\"Labels:\" ,y_test.unique())\n",
    "print(\"p0= For Each Label\",precision_score(y_test, predictions,average = None))\n",
    "print(\"r0= For Each Label\",recall_score(y_test, predictions,average = None))\n",
    "\n",
    "print(\"p0= Micro-average\",precision_score(y_test, predictions,average = 'micro'))\n",
    "print(\"r0= Micro-average\",recall_score(y_test, predictions,average = 'micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
